{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNqrKCG1wjruBjATLWGnwzw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["Текстовая ячейка <8-OfDI6lgM8k>\n","# %% [markdown]\n","**Варіант №1**\n","\n","Текстовая ячейка <n-ZHATzzgEre>\n","# %% [markdown]\n","**Завдання 1.** Побудова регресійної моделі та запобігання перенавчанню.\n","\n","Текстовая ячейка <qXYAfn3ngLnK>\n","# %% [markdown]\n","Необхідно побудувати регресійну модель на одному з вбудованих датасетів, доступних у\n","бібліотеці scikit-learn. Основна мета завдання — навчитися побудові регресійних\n","моделей та уникненню перенавчання (overfitting) шляхом застосування відповідних\n","технік.\n","\n","Кодовая ячейка <qlvMPFGWmUSH>\n","# %% [code]\n","from sklearn.datasets import load_wine\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","Кодовая ячейка <BRTn9TVhmudc>\n","# %% [code]\n","wine_data = load_wine()\n","\n","X = wine_data.data\n","y = wine_data.target\n","df = pd.DataFrame(X, columns=wine_data.feature_names)\n","df['target'] = y\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","df.head()\n","Получены выходные данные.\n","17KB\n","\ttext/plain\n","\t\talcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n","\t\t0    14.23        1.71  2.43               15.6      127.0           2.80\n","\t\t1    13.20        1.78  2.14               11.2      100.0           2.65\n","\t\t2    13.16        2.36  2.67               18.6      101.0           2.80\n","\t\t3    14.37        1.95  2.50               16.8      113.0           3.85\n","\t\t4    13.24        2.59  2.87               21.0      118.0           2.80\n","\n","\t\t   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n","\t\t0        3.06                  0.28             2.29             5.64  1.04\n","\t\t1        2.76                  0.26             1.28             4.38  1.05\n","\t\t2        3.24                  0.30             2.81             5.68  1.03\n","\t\t3        3.49                  0.24             2.18             7.80  0.86\n","\t\t4        2.69                  0.39             1.82             4.32  1.04\n","\n","\t\t   od280/od315_of_diluted_wines  proline  target\n","\t\t0                          3.92   1065.0       0\n","\t\t1                          3.40   1050.0       0\n","\t\t2                          3.17   1185.0       0\n","\t\t3                          3.45   1480.0       0\n","\t\t4                          2.93    735.0       0\n","\n","Кодовая ячейка <LNkN0T2zm2Hi>\n","# %% [code]\n","#Побудова регресійної моделі\n","\n","lr_model = LinearRegression()\n","lr_model.fit(X_train, y_train)\n","y_train_pred = lr_model.predict(X_train)\n","y_test_pred = lr_model.predict(X_test)\n","\n","train_mse = mean_squared_error(y_train, y_train_pred)\n","test_mse = mean_squared_error(y_test, y_test_pred)\n","train_r2 = r2_score(y_train, y_train_pred)\n","test_r2 = r2_score(y_test, y_test_pred)\n","\n","print(f\"Базова модель (Лінійна регресія):\")\n","print(f\"Навчальні дані: MSE = {train_mse:.2f}, R^2 = {train_r2:.2f}\")\n","print(f\"Тестові дані: MSE = {test_mse:.2f}, R^2 = {test_r2:.2f}\")\n","Получены выходные данные.\n","0KB\n","\tStream\n","\t\tБазова модель (Лінійна регресія):\n","\t\tНавчальні дані: MSE = 0.06, R^2 = 0.90\n","\t\tТестові дані: MSE = 0.06, R^2 = 0.90\n","\n","Кодовая ячейка <fdyfnvIGnHBu>\n","# %% [code]\n","# 2. Запобігання перенавчанню з використанням регуляризації\n","alphas = np.logspace(0, 4, 100)  # Діапазон значень для параметра регуляризації\n","\n","# Ridge Regression\n","ridge_cv_scores = []\n","for alpha in alphas:\n","    ridge_model = Ridge(alpha=alpha)\n","    ridge_model.fit(X_train, y_train)\n","    scores = cross_val_score(ridge_model, X, y, cv=5, scoring='neg_mean_squared_error')\n","    ridge_cv_scores.append(-scores.mean())\n","\n","Кодовая ячейка <K4Jm6IfWnN7K>\n","# %% [code]\n","# Лассо Regression\n","lasso_cv_scores = []\n","for alpha in alphas:\n","    lasso_model = Lasso(alpha=alpha)\n","    lasso_model.fit(X_train, y_train)\n","    scores = cross_val_score(lasso_model, X, y, cv=5, scoring='neg_mean_squared_error')\n","    lasso_cv_scores.append(-scores.mean())\n","\n","# Вибір кращих моделей за допомогою перехресної валідації\n","best_ridge_alpha = alphas[np.argmin(ridge_cv_scores)]\n","best_lasso_alpha = alphas[np.argmin(lasso_cv_scores)]\n","\n","print(f\"Найкраще значення alpha для Ridge: {best_ridge_alpha}\")\n","print(f\"Найкраще значення alpha для Lasso: {best_lasso_alpha}\")\n","Получены выходные данные.\n","0KB\n","\tStream\n","\t\tНайкраще значення alpha для Ridge: 7.054802310718643\n","\t\tНайкраще значення alpha для Lasso: 1.0\n","\n","Кодовая ячейка <Pcf8OxRnnYBd>\n","# %% [code]\n","# Переоцінка моделей на тестових даних\n","\n","ridge_model = Ridge(alpha=best_ridge_alpha)\n","ridge_model.fit(X_train, y_train)\n","ridge_y_test_pred = ridge_model.predict(X_test)\n","\n","lasso_model = Lasso(alpha=best_lasso_alpha)\n","lasso_model.fit(X_train, y_train)\n","lasso_y_test_pred = lasso_model.predict(X_test)\n","\n","# Оцінка моделей з регуляризацією\n","\n","ridge_test_mse = mean_squared_error(y_test, ridge_y_test_pred)\n","lasso_test_mse = mean_squared_error(y_test, lasso_y_test_pred)\n","ridge_test_r2 = r2_score(y_test, ridge_y_test_pred)\n","lasso_test_r2 = r2_score(y_test, lasso_y_test_pred)\n","\n","print(f\"Ridge Regression: MSE = {ridge_test_mse:.2f}, R^2 = {ridge_test_r2:.2f}\")\n","print(f\"Lasso Regression: MSE = {lasso_test_mse:.2f}, R^2 = {lasso_test_r2:.2f}\")\n","Получены выходные данные.\n","0KB\n","\tStream\n","\t\tRidge Regression: MSE = 0.06, R^2 = 0.90\n","\t\tLasso Regression: MSE = 0.33, R^2 = 0.45\n","\n","Кодовая ячейка <ygwuF3HZnhDl>\n","# %% [code]\n","# Візуалізація результатів\n","\n","plt.figure(figsize=(5, 3))\n","plt.semilogx(alphas, ridge_cv_scores, label='Ridge')\n","plt.semilogx(alphas, lasso_cv_scores, label='Lasso')\n","plt.xlabel('Alpha')\n","plt.ylabel('Cross-validated MSE')\n","plt.title('Перехресна валідація для Ridge та Lasso')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","Получены выходные данные.\n","32KB\n","\ttext/plain\n","\t\t<Figure size 500x300 with 1 Axes>\n","\n","Текстовая ячейка <-e_DMANinsL_>\n","# %% [markdown]\n","**ВИСНОВОК**\n","\n","Було обрано один із датасетів бібліотеки scikit-learn \"Wine\". На основі навчальнох вибірки побудовано базову лінійну регресійну модель та була оцінена її точність. Також виконано аналіз перенавчання. Лінійна та Ridge регресії є кращим вибором. Також побудрвано графік, який демонструє залежність помилки моделі від\n","гіперпараметрів регуляризації.\n","\n","Текстовая ячейка <OerIm5JXo2fW>\n","# %% [markdown]\n","**Завдання 2.** Виконати кластерізацію даних. Затосувати метод ліктя або метод силуєтів.\n","Зробити візуалізацію кластерів.\n","\n","\n","Кодовая ячейка <SuqyiN9jo_do>\n","# %% [code]\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import StandardScaler\n","import seaborn as sns\n","\n","Кодовая ячейка <l3DFhJJ_pC7I>\n","# %% [code]\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","X_2d = pd.DataFrame(X_scaled, columns=wine_data.feature_names)\n","\n","wcss_2d = []\n","for i in range(1, 11):\n","    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n","    kmeans.fit(X_2d)\n","    wcss_2d.append(kmeans.inertia_)\n","\n","plt.figure(figsize=(7, 5))\n","plt.plot(range(1, 11), wcss_2d, marker='o', linestyle='--')\n","plt.title('Elbow Method after scaling')\n","plt.xlabel('Number of clusters')\n","plt.ylabel('Within-clusters Sum of Squares')\n","plt.grid(True)\n","plt.show()\n","Получены выходные данные.\n","43KB\n","\ttext/plain\n","\t\t<Figure size 700x500 with 1 Axes>\n","\n","Кодовая ячейка <_ncVmPmjppdF>\n","# %% [code]\n","kmeans = KMeans(n_clusters=2, init='k-means++', max_iter=300, n_init=10, random_state=42)\n","clusters = kmeans.fit_predict(X_scaled)\n","\n","plt.figure(figsize=(7,5))\n","sns.scatterplot(x=X_scaled[:,0], y=X_scaled[:,1], hue=clusters, palette='viridis', legend='full')\n","plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s=300, c='red', label='Centroids')\n","plt.title('KMeans Clusterint')\n","plt.xlabel('Feature 1 (Scaled)')\n","plt.ylabel('Feature 2 (Scaled)')\n","plt.legend(title='Cluster')\n","plt.grid(True)\n","plt.show()\n","Получены выходные данные.\n","67KB\n","\ttext/plain\n","\t\t<Figure size 700x500 with 1 Axes>\n","\n","Текстовая ячейка <WqsQADT0p2BT>\n","# %% [markdown]\n","**ВИСНОВОК **\n","\n","Виконали кластерізацію даних. Затосували метод ліктя або метод силуєтів.\n","У підсумку у нас вийшла графічна візуалізація яка показує наш аналіз.\n","\n","\n"],"metadata":{"id":"2AfxS8zOy4jn"},"execution_count":null,"outputs":[]}]}