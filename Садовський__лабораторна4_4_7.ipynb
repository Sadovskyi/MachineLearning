{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOltHT48/zM63enArbM7e2r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"Tgcv8uyFv_hP"}},{"cell_type":"code","source":["Текстовая ячейка <g1rHAG97fBr9>\n","# %% [markdown]\n","**Варіант №1**\n","\n","Кодовая ячейка <5DGrc7GPff7W>\n","# %% [code]\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.svm import SVC\n","\n","Текстовая ячейка <Xno4_MA6fGVx>\n","# %% [markdown]\n","**Завдання 1**\n","\n","Текстовая ячейка <DoM7WTmSfRn2>\n","# %% [markdown]\n","1. Завантажте вбудований датасет load_breast_cancer з бібліотеки\n","sklearn.datasets.\n","\n","Кодовая ячейка <LkxhRjCtfS8d>\n","# %% [code]\n","from sklearn.datasets import load_breast_cancer\n","import pandas as pd\n","\n","data = load_breast_cancer()\n","\n","df = pd.DataFrame(data.data, columns=data.feature_names)\n","df['target'] = data.target\n","\n","df.head()\n","Получены выходные данные.\n","14KB\n","\ttext/plain\n","\t\tmean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n","\t\t0        17.99         10.38          122.80     1001.0          0.11840\n","\t\t1        20.57         17.77          132.90     1326.0          0.08474\n","\t\t2        19.69         21.25          130.00     1203.0          0.10960\n","\t\t3        11.42         20.38           77.58      386.1          0.14250\n","\t\t4        20.29         14.34          135.10     1297.0          0.10030\n","\n","\t\t   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n","\t\t0           0.27760          0.3001              0.14710         0.2419\n","\t\t1           0.07864          0.0869              0.07017         0.1812\n","\t\t2           0.15990          0.1974              0.12790         0.2069\n","\t\t3           0.28390          0.2414              0.10520         0.2597\n","\t\t4           0.13280          0.1980              0.10430         0.1809\n","\n","\t\t   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n","\t\t0                 0.07871  ...          17.33           184.60      2019.0\n","\t\t1                 0.05667  ...          23.41           158.80      1956.0\n","\t\t2                 0.05999  ...          25.53           152.50      1709.0\n","\t\t3                 0.09744  ...          26.50            98.87       567.7\n","\t\t4                 0.05883  ...          16.67           152.20      1575.0\n","\n","\t\t   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n","\t\t0            0.1622             0.6656           0.7119                0.2654\n","\t\t1            0.1238             0.1866           0.2416                0.1860\n","\t\t2            0.1444             0.4245           0.4504                0.2430\n","\t\t3            0.2098             0.8663           0.6869                0.2575\n","\t\t4            0.1374             0.2050           0.4000                0.1625\n","\n","\t\t   worst symmetry  worst fractal dimension  target\n","\t\t0          0.4601                  0.11890       0\n","\t\t1          0.2750                  0.08902       0\n","\t\t2          0.3613                  0.08758       0\n","\t\t3          0.6638                  0.17300       0\n","\t\t4          0.2364                  0.07678       0\n","\n","\t\t[5 rows x 31 columns]\n","\n","Текстовая ячейка <Ga-WEgDBf8c7>\n","# %% [markdown]\n","2. Проведіть попередній аналіз даних:\n","    1. Перегляньте перші кілька рядків.\n","    2. Перевірте назви стовпців та типи даних.\n","    3. Перевірте наявність пропущених значень.\n","    4. Досліджуйте розмір даних\n","\n","Кодовая ячейка <_1A-yoKGgD3_>\n","# %% [code]\n","print(\"Перші 5 рядків:\")\n","df.head()\n","\n","Получены выходные данные.\n","14KB\n","\tStream\n","\t\tПерші 5 рядків:\n","\ttext/plain\n","\t\tmean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n","\t\t0        17.99         10.38          122.80     1001.0          0.11840\n","\t\t1        20.57         17.77          132.90     1326.0          0.08474\n","\t\t2        19.69         21.25          130.00     1203.0          0.10960\n","\t\t3        11.42         20.38           77.58      386.1          0.14250\n","\t\t4        20.29         14.34          135.10     1297.0          0.10030\n","\n","\t\t   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n","\t\t0           0.27760          0.3001              0.14710         0.2419\n","\t\t1           0.07864          0.0869              0.07017         0.1812\n","\t\t2           0.15990          0.1974              0.12790         0.2069\n","\t\t3           0.28390          0.2414              0.10520         0.2597\n","\t\t4           0.13280          0.1980              0.10430         0.1809\n","\n","\t\t   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n","\t\t0                 0.07871  ...          17.33           184.60      2019.0\n","\t\t1                 0.05667  ...          23.41           158.80      1956.0\n","\t\t2                 0.05999  ...          25.53           152.50      1709.0\n","\t\t3                 0.09744  ...          26.50            98.87       567.7\n","\t\t4                 0.05883  ...          16.67           152.20      1575.0\n","\n","\t\t   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n","\t\t0            0.1622             0.6656           0.7119                0.2654\n","\t\t1            0.1238             0.1866           0.2416                0.1860\n","\t\t2            0.1444             0.4245           0.4504                0.2430\n","\t\t3            0.2098             0.8663           0.6869                0.2575\n","\t\t4            0.1374             0.2050           0.4000                0.1625\n","\n","\t\t   worst symmetry  worst fractal dimension  target\n","\t\t0          0.4601                  0.11890       0\n","\t\t1          0.2750                  0.08902       0\n","\t\t2          0.3613                  0.08758       0\n","\t\t3          0.6638                  0.17300       0\n","\t\t4          0.2364                  0.07678       0\n","\n","\t\t[5 rows x 31 columns]\n","\n","Кодовая ячейка <lfzlkeRqgYn6>\n","# %% [code]\n","print(\"\\nНазви стовпців і типи даних:\")\n","df.dtypes\n","Получены выходные данные.\n","5KB\n","\tStream\n","\t\tНазви стовпців і типи даних:\n","\ttext/plain\n","\t\tmean radius                float64\n","\t\tmean texture               float64\n","\t\tmean perimeter             float64\n","\t\tmean area                  float64\n","\t\tmean smoothness            float64\n","\t\tmean compactness           float64\n","\t\tmean concavity             float64\n","\t\tmean concave points        float64\n","\t\tmean symmetry              float64\n","\t\tmean fractal dimension     float64\n","\t\tradius error               float64\n","\t\ttexture error              float64\n","\t\tperimeter error            float64\n","\t\tarea error                 float64\n","\t\tsmoothness error           float64\n","\t\tcompactness error          float64\n","\t\tconcavity error            float64\n","\t\tconcave points error       float64\n","\t\tsymmetry error             float64\n","\t\tfractal dimension error    float64\n","\t\tworst radius               float64\n","\t\tworst texture              float64\n","\t\tworst perimeter            float64\n","\t\tworst area                 float64\n","\t\tworst smoothness           float64\n","\t\tworst compactness          float64\n","\t\tworst concavity            float64\n","\t\tworst concave points       float64\n","\t\tworst symmetry             float64\n","\t\tworst fractal dimension    float64\n","\t\ttarget                       int64\n","\t\tdtype: object\n","\n","Кодовая ячейка <fnjO241LgbZH>\n","# %% [code]\n","print(\"\\nПропущені значення:\")\n","df.isnull().sum()\n","Получены выходные данные.\n","4KB\n","\tStream\n","\t\tПропущені значення:\n","\ttext/plain\n","\t\tmean radius                0\n","\t\tmean texture               0\n","\t\tmean perimeter             0\n","\t\tmean area                  0\n","\t\tmean smoothness            0\n","\t\tmean compactness           0\n","\t\tmean concavity             0\n","\t\tmean concave points        0\n","\t\tmean symmetry              0\n","\t\tmean fractal dimension     0\n","\t\tradius error               0\n","\t\ttexture error              0\n","\t\tperimeter error            0\n","\t\tarea error                 0\n","\t\tsmoothness error           0\n","\t\tcompactness error          0\n","\t\tconcavity error            0\n","\t\tconcave points error       0\n","\t\tsymmetry error             0\n","\t\tfractal dimension error    0\n","\t\tworst radius               0\n","\t\tworst texture              0\n","\t\tworst perimeter            0\n","\t\tworst area                 0\n","\t\tworst smoothness           0\n","\t\tworst compactness          0\n","\t\tworst concavity            0\n","\t\tworst concave points       0\n","\t\tworst symmetry             0\n","\t\tworst fractal dimension    0\n","\t\ttarget                     0\n","\t\tdtype: int64\n","\n","Кодовая ячейка <dHk1z0dlghJh>\n","# %% [code]\n","print(\"\\nРозмір даних:\")\n","df.shape\n","Получены выходные данные.\n","0KB\n","\tStream\n","\t\tРозмір даних:\n","\ttext/plain\n","\t\t(569, 31)\n","\n","Текстовая ячейка <irtFeOP_gqiL>\n","# %% [markdown]\n","2. Побудова і налаштування моделей:\n","    1. Розділіть дані на навчальний і тестовий набори.\n","    2. Побудуйте три моделі класифікації (на власний вибір),\n","    наприклад:\n","        1. Логістична регресія.\n","        2. Дерево рішень.\n","        3. Випадковий ліс (Random Forest).\n","    3. Підберіть оптимальні параметри для кожної моделі за допомогою\n","GridSearchCV (можна вибрати інший оптимізатор).\n","\n","Текстовая ячейка <Ndgg8cTjhqux>\n","# %% [markdown]\n","Розділіть дані на навчальний і тестовий набори.\n","\n","Кодовая ячейка <BhK3pIU3gyZu>\n","# %% [code]\n","from sklearn.model_selection import train_test_split\n","\n","X, y = data.data, data.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","print(\"Розмір навчального набору (X_train):\", X_train.shape)\n","print(\"Розмір тестового набору (X_test):\", X_test.shape)\n","print(\"Розмір навчальних міток (y_train):\", y_train.shape)\n","print(\"Розмір тестових міток (y_test):\", y_test.shape)\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","Получены выходные данные.\n","0KB\n","\tStream\n","\t\tРозмір навчального набору (X_train): (398, 30)\n","\t\tРозмір тестового набору (X_test): (171, 30)\n","\t\tРозмір навчальних міток (y_train): (398,)\n","\t\tРозмір тестових міток (y_test): (171,)\n","\n","Текстовая ячейка <bYClqGvQhxvB>\n","# %% [markdown]\n","Логістична регресія\n","\n","Кодовая ячейка <i7fuAVdxh1hJ>\n","# %% [code]\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","logreg = LogisticRegression(max_iter=1000)\n","\n","logreg_params = {\n","    'C': [0.1, 1, 10],\n","    'penalty': ['l2']\n","}\n","\n","logreg_grid = GridSearchCV(logreg, logreg_params, cv=5)\n","logreg_grid.fit(X_train, y_train)\n","logreg_best = logreg_grid.best_estimator_\n","y_pred = logreg_best.predict(X_test)\n","\n","print(\"Точність на тестовому наборі: \", accuracy_score(y_test, y_pred))\n","print(\"Найкращі параметри: \", logreg_grid.best_params_)\n","\n","Получены выходные данные.\n","0KB\n","\tStream\n","\t\tТочність на тестовому наборі:  0.9824561403508771\n","\t\tНайкращі параметри:  {'C': 1, 'penalty': 'l2'}\n","\n","Текстовая ячейка <3SdIWDGZjQrl>\n","# %% [markdown]\n","Дерево рішень\n","\n","Кодовая ячейка <6ZxcaI2njSsD>\n","# %% [code]\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","tree = DecisionTreeClassifier(random_state=42)\n","\n","tree_params = {\n","    'max_depth': [3, 5, 7],\n","    'min_samples_split': [2, 5, 10]\n","}\n","\n","tree_grid = GridSearchCV(tree, tree_params, cv=5)\n","tree_grid.fit(X_train, y_train)\n","tree_best = tree_grid.best_estimator_\n","\n","y_pred_tree = tree_best.predict(X_test)\n","\n","print(\"Точність дерева рішень на тестовому наборі: \", accuracy_score(y_test, y_pred_tree))\n","print(\"Найкращі параметри для дерева рішень: \", tree_grid.best_params_)\n","Получены выходные данные.\n","0KB\n","\tStream\n","\t\tТочність дерева рішень на тестовому наборі:  0.9649122807017544\n","\t\tНайкращі параметри для дерева рішень:  {'max_depth': 3, 'min_samples_split': 2}\n","\n","Текстовая ячейка <ADdM1Y7bkLeN>\n","# %% [markdown]\n","Випадковий ліс (Random Forest)\n","\n","Кодовая ячейка <T9YRITD_kNn5>\n","# %% [code]\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","rf = RandomForestClassifier(random_state=42)\n","rf_params = {\n","    'n_estimators': [50, 100, 150],\n","    'max_depth': [None, 10, 20],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","rf_grid = GridSearchCV(rf, rf_params, cv=5)\n","rf_grid.fit(X_train, y_train)\n","rf_best = rf_grid.best_estimator_\n","y_pred_rf = rf_best.predict(X_test)\n","\n","print(\"Точність випадкового лісу на тестовому наборі: \", accuracy_score(y_test, y_pred_rf))\n","print(\"Найкращі параметри для випадкового лісу: \", rf_grid.best_params_)\n","\n","Получены выходные данные.\n","0KB\n","\tStream\n","\t\tТочність випадкового лісу на тестовому наборі:  0.9707602339181286\n","\t\tНайкращі параметри для випадкового лісу:  {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 150}\n","\n","Текстовая ячейка <X7f0Cryll3Z1>\n","# %% [markdown]\n","Підберіть оптимальні параметри для кожної моделі за допомогою\n","GridSearchCV (можна вибрати інший оптимізатор).\n","\n","Кодовая ячейка <aaMJ456tmaUx>\n","# %% [code]\n","svm = SVC()\n","svm_params = {\n","    'C': [0.1, 1, 10],\n","    'kernel': ['linear', 'rbf'],\n","    'gamma': ['scale', 'auto']\n","}\n","\n","svm_grid = GridSearchCV(svm, svm_params, cv=5)\n","svm_grid.fit(X_train, y_train)\n","svm_best = svm_grid.best_estimator_\n","\n","models = {'Logistic Regression': logreg_best, 'Decision Tree': tree_best, 'SVM': svm_best}\n","\n","for model_name, model in models.items():\n","    y_pred = model.predict(X_test)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"{model_name} Accuracy: {accuracy}\")\n","Получены выходные данные.\n","0KB\n","\tStream\n","\t\tLogistic Regression Accuracy: 0.9824561403508771\n","\t\tDecision Tree Accuracy: 0.9649122807017544\n","\t\tSVM Accuracy: 0.9824561403508771\n","\n","Кодовая ячейка <G70T0NVlmH7V>\n","# %% [code]\n","import pandas as pd\n","\n","best_params = {\n","    'Model': ['Logistic Regression', 'Decision Tree', 'SVM'],\n","    'Best Parameters': [\n","        logreg_grid.best_params_,\n","        tree_grid.best_params_,\n","        svm_grid.best_params_\n","    ]\n","}\n","best_params_df = pd.DataFrame(best_params)\n","best_params_df\n","Получены выходные данные.\n","9KB\n","\ttext/plain\n","\t\tModel                                   Best Parameters\n","\t\t0  Logistic Regression                         {'C': 1, 'penalty': 'l2'}\n","\t\t1        Decision Tree          {'max_depth': 3, 'min_samples_split': 2}\n","\t\t2                  SVM  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n","\n","Текстовая ячейка <FLnEtnxkmqMH>\n","# %% [markdown]\n","3. Оцініть моделі. Виведіть точність (accuracy) – обов’язково, матрицю\n","помилок (confusion matrix) – за вибором та звіт про класифікацію\n","(classification report) для кожної моделі\n","\n","Кодовая ячейка <B6op-5csmrRY>\n","# %% [code]\n","for model_name, model in models.items():\n","    print(f\"Model: {model_name}\")\n","    y_pred = model.predict(X_test)\n","    print(classification_report(y_test, y_pred))\n","    print('-' * 60)\n","Получены выходные данные.\n","2KB\n","\tStream\n","\t\tModel: Logistic Regression\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       0.97      0.98      0.98        63\n","\t\t           1       0.99      0.98      0.99       108\n","\n","\t\t    accuracy                           0.98       171\n","\t\t   macro avg       0.98      0.98      0.98       171\n","\t\tweighted avg       0.98      0.98      0.98       171\n","\n","\t\t------------------------------------------------------------\n","\t\tModel: Decision Tree\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       0.97      0.94      0.95        63\n","\t\t           1       0.96      0.98      0.97       108\n","\n","\t\t    accuracy                           0.96       171\n","\t\t   macro avg       0.97      0.96      0.96       171\n","\t\tweighted avg       0.96      0.96      0.96       171\n","\n","\t\t------------------------------------------------------------\n","\t\tModel: Random Forest\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       0.98      0.94      0.96        63\n","\t\t           1       0.96      0.99      0.98       108\n","\n","\t\t    accuracy                           0.97       171\n","\t\t   macro avg       0.97      0.96      0.97       171\n","\t\tweighted avg       0.97      0.97      0.97       171\n","\n","\t\t------------------------------------------------------------\n","\t\tModel: SVM\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       0.98      0.97      0.98        63\n","\t\t           1       0.98      0.99      0.99       108\n","\n","\t\t    accuracy                           0.98       171\n","\t\t   macro avg       0.98      0.98      0.98       171\n","\t\tweighted avg       0.98      0.98      0.98       171\n","\n","\t\t------------------------------------------------------------\n","\n","Кодовая ячейка <aKphgVrtnHPs>\n","# %% [code]\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","models = {\n","    'Logistic Regression': logreg_best,\n","    'Decision Tree': tree_best,\n","    'Random Forest': rf_best,\n","    'SVM': svm_best\n","}\n","\n","for model_name, model in models.items():\n","    print(f\"Model: {model_name}\")\n","\n","    y_pred = model.predict(X_test)\n","\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","\n","    print(\"Classification Report:\")\n","    print(classification_report(y_test, y_pred))\n","\n","    cm = confusion_matrix(y_test, y_pred)\n","    plt.figure(figsize=(1, 1))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n","    plt.title(f\"Confusion Matrix for {model_name}\")\n","    plt.xlabel('Predicted Label')\n","    plt.ylabel('True Label')\n","    plt.show()\n","\n","    print('-' * 60)\n","\n","Получены выходные данные.\n","84KB\n","\tStream\n","\t\tModel: Logistic Regression\n","\t\tAccuracy: 0.9825\n","\t\tClassification Report:\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       0.97      0.98      0.98        63\n","\t\t           1       0.99      0.98      0.99       108\n","\n","\t\t    accuracy                           0.98       171\n","\t\t   macro avg       0.98      0.98      0.98       171\n","\t\tweighted avg       0.98      0.98      0.98       171\n","\t\t------------------------------------------------------------\n","\t\tModel: Decision Tree\n","\t\tAccuracy: 0.9649\n","\t\tClassification Report:\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       0.97      0.94      0.95        63\n","\t\t           1       0.96      0.98      0.97       108\n","\n","\t\t    accuracy                           0.96       171\n","\t\t   macro avg       0.97      0.96      0.96       171\n","\t\tweighted avg       0.96      0.96      0.96       171\n","\t\t------------------------------------------------------------\n","\t\tModel: Random Forest\n","\t\tAccuracy: 0.9708\n","\t\tClassification Report:\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       0.98      0.94      0.96        63\n","\t\t           1       0.96      0.99      0.98       108\n","\n","\t\t    accuracy                           0.97       171\n","\t\t   macro avg       0.97      0.96      0.97       171\n","\t\tweighted avg       0.97      0.97      0.97       171\n","\t\t------------------------------------------------------------\n","\t\tModel: SVM\n","\t\tAccuracy: 0.9825\n","\t\tClassification Report:\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       0.98      0.97      0.98        63\n","\t\t           1       0.98      0.99      0.99       108\n","\n","\t\t    accuracy                           0.98       171\n","\t\t   macro avg       0.98      0.98      0.98       171\n","\t\tweighted avg       0.98      0.98      0.98       171\n","\t\t------------------------------------------------------------\n","\ttext/plain\n","\t\t<Figure size 100x100 with 2 Axes>\n","\t\t<Figure size 100x100 with 2 Axes>\n","\t\t<Figure size 100x100 with 2 Axes>\n","\t\t<Figure size 100x100 with 2 Axes>\n","\n","Текстовая ячейка <EbUABTVenawS>\n","# %% [markdown]\n","4. Прогнозування і висновки\n","    1. Оберіть найкращу модель на основі метрик продуктивності.\n","    2. Зробіть прогноз на тестовій вибірці.\n","    3. Виведіть результати прогнозування.\n","\n","Кодовая ячейка <eibN9wMZsDO1>\n","# %% [code]\n","import numpy as np\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","best_params = {'C': 0.1, 'penalty': 'l2'}\n","logreg = LogisticRegression(**best_params, max_iter=1000)\n","logreg.fit(X_train, y_train)\n","\n","np.random.seed(42)\n","random_indices = np.random.choice(X_test.shape[0], 10, replace=False)\n","X_random = X_test[random_indices]\n","y_random_actual = y_test[random_indices]\n","\n","y_random_pred = logreg.predict(X_random)\n","\n","comparison_df = pd.DataFrame({\n","    'Sample Index': random_indices,\n","    'Real Class': y_random_actual,\n","    'Predicted Class': y_random_pred\n","})\n","\n","comparison_df\n","Получены выходные данные.\n","11KB\n","\ttext/plain\n","\t\tSample Index  Real Class  Predicted Class\n","\t\t0           101           1                1\n","\t\t1            55           1                1\n","\t\t2            56           1                1\n","\t\t3           139           0                0\n","\t\t4           157           1                1\n","\t\t5            78           1                1\n","\t\t6           135           0                0\n","\t\t7           104           1                1\n","\t\t8           109           1                1\n","\t\t9           108           1                1\n","\n","Текстовая ячейка <BxHwa4SMtE54>\n","# %% [markdown]\n","**ВИСНОВОК**\n","\n","Найкраща модель на основі метрик продуктивності: логістична регресія і SVM мають найвищу точність (0.9825)\n","\n","Модель логістичної регресії правильно передбачила класи для всіх 10 випадкових зразків з тестової вибірки. Це свідчить про високу точність моделі на цих зразках.\n","\n","Текстовая ячейка <pN70ehlutuz6>\n","# %% [markdown]\n","**Завдання 2**\n","\n","Текстовая ячейка <1rK7BAGSt5RO>\n","# %% [markdown]\n","Завантажуємо датасет **titanic.csv**\n","\n","Кодовая ячейка <yGFX_jkDvTlm>\n","# %% [code]\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.svm import SVC\n","\n","Кодовая ячейка <FiwYly3ivV2E>\n","# %% [code]\n","import pandas as pd\n","\n","from google.colab import files\n","uploaded = files.upload()\n","Получены выходные данные.\n","6KB\n","\tStream\n","\t\tSaving titanic.csv to titanic (1).csv\n","\n","Кодовая ячейка <2evL0RvtwTxQ>\n","# %% [code]\n","df = pd.read_csv('titanic (2).csv')\n","\n","print(\"Перші 5 рядків датасету:\")\n","df.head()\n","Получены выходные данные.\n","15KB\n","\tStream\n","\t\tПерші 5 рядків датасету:\n","\ttext/plain\n","\t\tPassengerId  Survived  Pclass  \\\n","\t\t0          892         0       3\n","\t\t1          893         1       3\n","\t\t2          894         0       2\n","\t\t3          895         0       3\n","\t\t4          896         1       3\n","\n","\t\t                                           Name     Sex   Age  SibSp  Parch  \\\n","\t\t0                              Kelly, Mr. James    male  34.5      0      0\n","\t\t1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0\n","\t\t2                     Myles, Mr. Thomas Francis    male  62.0      0      0\n","\t\t3                              Wirz, Mr. Albert    male  27.0      0      0\n","\t\t4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1\n","\n","\t\t    Ticket     Fare Cabin Embarked\n","\t\t0   330911   7.8292   NaN        Q\n","\t\t1   363272   7.0000   NaN        S\n","\t\t2   240276   9.6875   NaN        Q\n","\t\t3   315154   8.6625   NaN        S\n","\t\t4  3101298  12.2875   NaN        S\n","\n","Кодовая ячейка <Pm86Q4D7xJNH>\n","# %% [code]\n","df.dtypes\n","Получены выходные данные.\n","2KB\n","\ttext/plain\n","\t\tPassengerId      int64\n","\t\tSurvived         int64\n","\t\tPclass           int64\n","\t\tName            object\n","\t\tSex             object\n","\t\tAge            float64\n","\t\tSibSp            int64\n","\t\tParch            int64\n","\t\tTicket          object\n","\t\tFare           float64\n","\t\tCabin           object\n","\t\tEmbarked        object\n","\t\tdtype: object\n","\n","Кодовая ячейка <c1gJrLPZxLHP>\n","# %% [code]\n","df.isnull().sum()\n","Получены выходные данные.\n","2KB\n","\ttext/plain\n","\t\tPassengerId      0\n","\t\tSurvived         0\n","\t\tPclass           0\n","\t\tName             0\n","\t\tSex              0\n","\t\tAge             86\n","\t\tSibSp            0\n","\t\tParch            0\n","\t\tTicket           0\n","\t\tFare             1\n","\t\tCabin          327\n","\t\tEmbarked         0\n","\t\tdtype: int64\n","\n","Кодовая ячейка <_u7bDCl-xN11>\n","# %% [code]\n","df.shape\n","Получены выходные данные.\n","0KB\n","\ttext/plain\n","\t\t(418, 12)\n","\n","Кодовая ячейка <zERCKnxXxdTJ>\n","# %% [code]\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","\n","df = pd.read_csv('titanic.csv')\n","\n","X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n","y = df['Survived']\n","\n","X = pd.get_dummies(X, columns=['Sex', 'Embarked'], drop_first=True)\n","imputer = SimpleImputer(strategy='mean')\n","X[['Age', 'Fare']] = imputer.fit_transform(X[['Age', 'Fare']])\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","print(\"Розмір навчального набору (X_train):\", X_train.shape)\n","print(\"Розмір тестового набору (X_test):\", X_test.shape)\n","print(\"Розмір навчальних міток (y_train):\", y_train.shape)\n","print(\"Розмір тестових міток (y_test):\", y_test.shape)\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","\n","Получены выходные данные.\n","0KB\n","\tStream\n","\t\tРозмір навчального набору (X_train): (292, 8)\n","\t\tРозмір тестового набору (X_test): (126, 8)\n","\t\tРозмір навчальних міток (y_train): (292,)\n","\t\tРозмір тестових міток (y_test): (126,)\n","\n","Текстовая ячейка <3IwEUVMzzBeG>\n","# %% [markdown]\n","Логістична регресія\n","\n","Кодовая ячейка <tqx7L3BRygre>\n","# %% [code]\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","logreg = LogisticRegression(max_iter=1000)\n","\n","logreg_params = {\n","    'C': [0.1, 1, 10],\n","    'penalty': ['l2']\n","}\n","\n","logreg_grid = GridSearchCV(logreg, logreg_params, cv=5)\n","logreg_grid.fit(X_train, y_train)\n","logreg_best = logreg_grid.best_estimator_\n","y_pred = logreg_best.predict(X_test)\n","\n","print(\"Точність на тестовому наборі: \", accuracy_score(y_test, y_pred))\n","print(\"Найкращі параметри: \", logreg_grid.best_params_)\n","Получены выходные данные.\n","0KB\n","\tStream\n","\t\tТочність на тестовому наборі:  1.0\n","\t\tНайкращі параметри:  {'C': 0.1, 'penalty': 'l2'}\n","\n","Текстовая ячейка <sXL1KduS1Fpu>\n","# %% [markdown]\n","Дерево рішень\n","\n","Кодовая ячейка <X594LTVq2vrQ>\n","# %% [code]\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","tree = DecisionTreeClassifier(random_state=42)\n","\n","tree_params = {\n","    'max_depth': [3, 5, 7],\n","    'min_samples_split': [2, 5, 10]\n","}\n","\n","tree_grid = GridSearchCV(tree, tree_params, cv=5)\n","tree_grid.fit(X_train, y_train)\n","tree_best = tree_grid.best_estimator_\n","\n","y_pred_tree = tree_best.predict(X_test)\n","\n","print(\"Точність дерева рішень на тестовому наборі: \", accuracy_score(y_test, y_pred_tree))\n","print(\"Найкращі параметри для дерева рішень: \", tree_grid.best_params_)\n","Получены выходные данные.\n","0KB\n","\tStream\n","\t\tТочність дерева рішень на тестовому наборі:  1.0\n","\t\tНайкращі параметри для дерева рішень:  {'max_depth': 3, 'min_samples_split': 2}\n","\n","Текстовая ячейка <mC4SQ1dj1Rlx>\n","# %% [markdown]\n","Метод опорних векторів (SVM)\n","\n","Кодовая ячейка <8RqHpyXj2Ar8>\n","# %% [code]\n","svm = SVC()\n","svm_params = {\n","    'C': [0.1, 1, 10],\n","    'kernel': ['linear', 'rbf'],\n","    'gamma': ['scale', 'auto']\n","}\n","\n","svm_grid = GridSearchCV(svm, svm_params, cv=5, n_jobs=-1)\n","svm_grid.fit(X_train, y_train)\n","svm_best = svm_grid.best_estimator_\n","\n","# Оцінка моделі\n","y_pred_svm = svm_best.predict(X_test)\n","svm_accuracy = accuracy_score(y_test, y_pred_svm)\n","svm_report = classification_report(y_test, y_pred_svm)\n","svm_best_params = svm_grid.best_params_\n","\n","print(\"Точність SVM на тестовому наборі: \", svm_accuracy)\n","print(\"Найкращі параметри для SVM: \", svm_best_params)\n","print(\"Звіт класифікації для SVM:\")\n","print(svm_report)\n","Получены выходные данные.\n","1KB\n","\tStream\n","\t\tТочність SVM на тестовому наборі:  1.0\n","\t\tНайкращі параметри для SVM:  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n","\t\tЗвіт класифікації для SVM:\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       1.00      1.00      1.00        85\n","\t\t           1       1.00      1.00      1.00        41\n","\n","\t\t    accuracy                           1.00       126\n","\t\t   macro avg       1.00      1.00      1.00       126\n","\t\tweighted avg       1.00      1.00      1.00       126\n","\n","Текстовая ячейка <wlqNXeMf2ejq>\n","# %% [markdown]\n","Оцінка моделей\n","\n","\n","Кодовая ячейка <SgD4XFKf2gBP>\n","# %% [code]\n","import pandas as pd\n","\n","best_params = {\n","    'Model': ['Logistic Regression', 'Decision Tree', 'SVM'],\n","    'Best Parameters': [\n","        logreg_grid.best_params_,\n","        tree_grid.best_params_,\n","        svm_grid.best_params_\n","    ]\n","}\n","best_params_df = pd.DataFrame(best_params)\n","best_params_df\n","Получены выходные данные.\n","9KB\n","\ttext/plain\n","\t\tModel                                   Best Parameters\n","\t\t0  Logistic Regression                       {'C': 0.1, 'penalty': 'l2'}\n","\t\t1        Decision Tree          {'max_depth': 3, 'min_samples_split': 2}\n","\t\t2                  SVM  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n","\n","Текстовая ячейка <S_3e1XSM3MpX>\n","# %% [markdown]\n","Виведіть точність (accuracy) – обов’язково, матрицю помилок (confusion matrix) – за вибором та звіт про класифікацію (classification report) для кожної моделі\n","\n","Кодовая ячейка <H9Bf1JBA3NHt>\n","# %% [code]\n","for model_name, model in models.items():\n","    print(f\"Model: {model_name}\")\n","    y_pred = model.predict(X_test)\n","    print(classification_report(y_test, y_pred))\n","    print('-' * 60)\n","Получены выходные данные.\n","1KB\n","\tStream\n","\t\tModel: Logistic Regression\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       1.00      1.00      1.00        85\n","\t\t           1       1.00      1.00      1.00        41\n","\n","\t\t    accuracy                           1.00       126\n","\t\t   macro avg       1.00      1.00      1.00       126\n","\t\tweighted avg       1.00      1.00      1.00       126\n","\n","\t\t------------------------------------------------------------\n","\t\tModel: Decision Tree\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       1.00      1.00      1.00        85\n","\t\t           1       1.00      1.00      1.00        41\n","\n","\t\t    accuracy                           1.00       126\n","\t\t   macro avg       1.00      1.00      1.00       126\n","\t\tweighted avg       1.00      1.00      1.00       126\n","\n","\t\t------------------------------------------------------------\n","\t\tModel: SVM\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       1.00      1.00      1.00        85\n","\t\t           1       1.00      1.00      1.00        41\n","\n","\t\t    accuracy                           1.00       126\n","\t\t   macro avg       1.00      1.00      1.00       126\n","\t\tweighted avg       1.00      1.00      1.00       126\n","\n","\t\t------------------------------------------------------------\n","\n","Кодовая ячейка <kPjUFTRP3amx>\n","# %% [code]\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","models = {\n","    'Logistic Regression': logreg_best,\n","    'Decision Tree': tree_best,\n","    'SVM': svm_best\n","}\n","\n","for model_name, model in models.items():\n","    print(f\"Model: {model_name}\")\n","\n","    y_pred = model.predict(X_test)\n","\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","\n","    print(\"Classification Report:\")\n","    print(classification_report(y_test, y_pred))\n","\n","    cm = confusion_matrix(y_test, y_pred)\n","    plt.figure(figsize=(1, 1))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n","    plt.title(f\"Confusion Matrix for {model_name}\")\n","    plt.xlabel('Predicted Label')\n","    plt.ylabel('True Label')\n","    plt.show()\n","\n","    print('-' * 60)\n","Получены выходные данные.\n","61KB\n","\tStream\n","\t\tModel: Logistic Regression\n","\t\tAccuracy: 1.0000\n","\t\tClassification Report:\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       1.00      1.00      1.00        85\n","\t\t           1       1.00      1.00      1.00        41\n","\n","\t\t    accuracy                           1.00       126\n","\t\t   macro avg       1.00      1.00      1.00       126\n","\t\tweighted avg       1.00      1.00      1.00       126\n","\t\t------------------------------------------------------------\n","\t\tModel: Decision Tree\n","\t\tAccuracy: 1.0000\n","\t\tClassification Report:\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       1.00      1.00      1.00        85\n","\t\t           1       1.00      1.00      1.00        41\n","\n","\t\t    accuracy                           1.00       126\n","\t\t   macro avg       1.00      1.00      1.00       126\n","\t\tweighted avg       1.00      1.00      1.00       126\n","\t\t------------------------------------------------------------\n","\t\tModel: SVM\n","\t\tAccuracy: 1.0000\n","\t\tClassification Report:\n","\t\t              precision    recall  f1-score   support\n","\n","\t\t           0       1.00      1.00      1.00        85\n","\t\t           1       1.00      1.00      1.00        41\n","\n","\t\t    accuracy                           1.00       126\n","\t\t   macro avg       1.00      1.00      1.00       126\n","\t\tweighted avg       1.00      1.00      1.00       126\n","\t\t------------------------------------------------------------\n","\ttext/plain\n","\t\t<Figure size 100x100 with 2 Axes>\n","\t\t<Figure size 100x100 with 2 Axes>\n","\t\t<Figure size 100x100 with 2 Axes>\n","\n","Текстовая ячейка <S9UYJUj-3mio>\n","# %% [markdown]\n","Прогнозування\n","\n","Кодовая ячейка <xhn1jCsQ3ok0>\n","# %% [code]\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","best_params = {'C': 0.1, 'penalty': 'l2'}\n","logreg = LogisticRegression(**best_params, max_iter=1000)\n","logreg.fit(X_train, y_train)\n","\n","np.random.seed(42)\n","random_indices = np.random.choice(X_test.shape[0], 10, replace=False)\n","\n","X_random = X_test[random_indices]\n","y_random_actual = y_test.iloc[random_indices]\n","\n","# Прогнозування\n","y_random_pred = logreg.predict(X_random)\n","\n","comparison_df = pd.DataFrame({\n","    'Sample Index': random_indices,\n","    'Real Class': y_random_actual.values,\n","    'Predicted Class': y_random_pred\n","})\n","\n","comparison_df\n","\n","Получены выходные данные.\n","11KB\n","\ttext/plain\n","\t\tSample Index  Real Class  Predicted Class\n","\t\t0            73           1                1\n","\t\t1            19           0                0\n","\t\t2           116           1                1\n","\t\t3            67           0                0\n","\t\t4            94           0                0\n","\t\t5            77           1                1\n","\t\t6            31           1                1\n","\t\t7            53           0                0\n","\t\t8           117           0                0\n","\t\t9            44           0                0\n","\n","Текстовая ячейка <oC940yW25MPt>\n","# %% [markdown]\n","**ВИСНОВОК**\n","\n","Для датасету titanic логістична регресія, дерево рішень і SVM працюють з точністю 100%. Вибірка з 10 випадків правильно передбачила класи зі всіма моделями. Оскільки всі моделі показали однакові результати, будь-яка з них може бути використана.\n","\n","\n"],"metadata":{"id":"IAUa-cDawbAi"},"execution_count":null,"outputs":[]}]}